{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LaHiru\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-2-19cdf4a31032>:94: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow library. Used to implement machine learning models\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#Numpy contains helpful functions for efficient mathematical calculations\n",
    "import numpy as np\n",
    "#Dataframe manipulation library\n",
    "import pandas as pd\n",
    "#Graph plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "test_base = pd.read_csv('unsubscribed_viu.txt', sep='|', encoding='unicode_escape')\n",
    "data = pd.read_csv('max_ratings.txt', sep='|', encoding='unicode_escape')\n",
    "\n",
    "\n",
    "data['RATING'] = pd.to_numeric(data['RATING'])\n",
    "data['RATING'] = data['RATING'].round()\n",
    "data = data.iloc[:150000, :]\n",
    "# data.head()\n",
    "\n",
    "data['RATING'] += 1\n",
    "# data.head()\n",
    "\n",
    "test_base.columns = ['MSISDN', 'USER_ID',]\n",
    "data.columns = ['USER_ID', 'TITLE', 'RATING']\n",
    "test_base.head()\n",
    "data.head()\n",
    "data['List Index'] = data.index\n",
    "data.head()\n",
    "\n",
    "\n",
    "#Merging movies_df with ratings_df by USER_ID\n",
    "merged_df = test_base.merge(data, on='USER_ID')\n",
    "merged_df = merged_df.sort_values([\"USER_ID\"], ascending=False)\n",
    "merged_df.head()\n",
    "\n",
    "\n",
    "#Group up by UserID\n",
    "userGroup = merged_df.groupby('USER_ID')\n",
    "userGroup.first().head()\n",
    "\n",
    "userGroup2 = merged_df.drop('RATING', axis=1).drop('TITLE', axis=1).drop('List Index', axis=1).drop('MSISDN', axis=1).drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "# print (userGroup2)\n",
    "  \n",
    "#Amount of users used for training\n",
    "amountOfUsers = len(userGroup2)\n",
    "#Creating the training list\n",
    "user_list= []\n",
    "# user_list = userGroup2['USER_ID'].tolist()\n",
    "# print (user_list)\n",
    "#Amount of users used for training\n",
    "amountOfUsedUsers = 1000\n",
    "#Creating the training list\n",
    "trX = []\n",
    "#For each user in the group\n",
    "for userID, curUser in userGroup:\n",
    "    #Create a temp that stores every movie's rating\n",
    "    temp = [0]*len(data)\n",
    "    #For each movie in curUser's movie list\n",
    "    for num, movie in curUser.iterrows():\n",
    "        #Divide the rating by 5 and store it\n",
    "        temp[movie['List Index']] = movie['RATING']/11.0\n",
    "    #Now add the list of ratings into the training list\n",
    "    trX.append(temp)\n",
    "    user_list.append(userID)\n",
    "    #Check to see if we finished adding in the amount of users for training\n",
    "    if amountOfUsedUsers == 0:\n",
    "        break\n",
    "    amountOfUsedUsers -= 1\n",
    "hiddenUnits = 20    \n",
    "visibleUnits = len(data)\n",
    "vb = tf.placeholder(\"float\", [visibleUnits]) #Number of unique movies\n",
    "hb = tf.placeholder(\"float\", [hiddenUnits]) #Number of features we're going to learn\n",
    "W = tf.placeholder(\"float\", [visibleUnits, hiddenUnits])\n",
    "\n",
    "#Phase 1: Input Processing\n",
    "v0 = tf.placeholder(\"float\", [None, visibleUnits])\n",
    "_h0= tf.nn.sigmoid(tf.matmul(v0, W) + hb)\n",
    "h0 = tf.nn.relu(tf.sign(_h0 - tf.random_uniform(tf.shape(_h0))))\n",
    "#Phase 2: Reconstruction\n",
    "_v1 = tf.nn.sigmoid(tf.matmul(h0, tf.transpose(W)) + vb) \n",
    "v1 = tf.nn.relu(tf.sign(_v1 - tf.random_uniform(tf.shape(_v1))))\n",
    "h1 = tf.nn.sigmoid(tf.matmul(v1, W) + hb)\n",
    "\n",
    "#Learning rate\n",
    "alpha = 1.0\n",
    "#Create the gradients\n",
    "w_pos_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "w_neg_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "#Calculate the Contrastive Divergence to maximize\n",
    "CD = (w_pos_grad - w_neg_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "#Create methods to update the weights and biases\n",
    "update_w = W + alpha * CD\n",
    "update_vb = vb + alpha * tf.reduce_mean(v0 - v1, 0)\n",
    "update_hb = hb + alpha * tf.reduce_mean(h0 - h1, 0)\n",
    "\n",
    "err = v0 - v1\n",
    "err_sum = tf.reduce_mean(err * err)\n",
    "\n",
    "#Current weight\n",
    "cur_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n",
    "#Current visible unit biases\n",
    "cur_vb = np.zeros([visibleUnits], np.float32)\n",
    "#Current hidden unit biases\n",
    "cur_hb = np.zeros([hiddenUnits], np.float32)\n",
    "#Previous weight\n",
    "prv_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n",
    "#Previous visible unit biases\n",
    "prv_vb = np.zeros([visibleUnits], np.float32)\n",
    "#Previous hidden unit biases\n",
    "prv_hb = np.zeros([hiddenUnits], np.float32)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "epochs = 5\n",
    "batchsize = 100\n",
    "errors = []\n",
    "for i in range(epochs):\n",
    "    for start, end in zip( range(0, len(trX), batchsize), range(batchsize, len(trX), batchsize)):\n",
    "        batch = trX[start:end]\n",
    "        cur_w = sess.run(update_w, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n",
    "        cur_vb = sess.run(update_vb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n",
    "        cur_nb = sess.run(update_hb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n",
    "        prv_w = cur_w\n",
    "        prv_vb = cur_vb\n",
    "        prv_hb = cur_nb\n",
    "    errors.append(sess.run(err_sum, feed_dict={v0: trX, W: cur_w, vb: cur_vb, hb: cur_nb})) \n",
    "# plt.plot(errors)\n",
    "# plt.ylabel('Error')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_similar(userID ,data):\n",
    "    #Selecting the input user\n",
    "    user = user_list.index(userID)\n",
    "#     print (user)\n",
    "    \n",
    "    inputUser = [trX[user]]\n",
    "    #userID = user_list[user]\n",
    "\n",
    "    #Feeding in the user and reconstructing the input\n",
    "    hh0 = tf.nn.sigmoid(tf.matmul(v0, W) + hb)\n",
    "    vv1 = tf.nn.sigmoid(tf.matmul(hh0, tf.transpose(W)) + vb)\n",
    "    feed = sess.run(hh0, feed_dict={ v0: inputUser, W: prv_w, hb: prv_hb})\n",
    "    rec = sess.run(vv1, feed_dict={ hh0: feed, W: prv_w, vb: prv_vb})\n",
    "    \n",
    "    #Getting the user watched movie list\n",
    "    user_data = data[data['USER_ID'] == userID]\n",
    "    watched_movies = user_data['TITLE'].to_list()\n",
    "    watched_list = user_data.drop('List Index', axis=1).drop('RATING', axis=1).drop('USER_ID', axis=1).head(5)\n",
    "#     print (watched_list)\n",
    "#     print('\\n')\n",
    "  \n",
    "    scored_movies_df = data\n",
    "    scored_movies_df[\"Recommendation Score\"] = rec[0]\n",
    "    \n",
    "    sorted_result = scored_movies_df.drop('List Index', axis=1)\n",
    "    Predicted_result = sorted_result.sort_values([\"Recommendation Score\"], ascending=False).drop('Recommendation Score', axis=1).drop('USER_ID', axis=1).drop('RATING', axis=1).head(5)\n",
    "#     print (Predicted_result)\n",
    "#     print('\\n')\n",
    "    \n",
    "    #Getting the recommended  movie list without the watched movies\n",
    "    recommendations = sorted_result[~sorted_result['TITLE'].isin(watched_movies)].sort_values([\"Recommendation Score\"], ascending=False)\n",
    "    recommended_result = recommendations.drop('Recommendation Score', axis=1).drop('USER_ID', axis=1).drop('RATING', axis=1).head(5)\n",
    "#     print (recommended_result)\n",
    "    \n",
    "    return watched_list, Predicted_result, recommended_result\n",
    "   \n",
    "x = get_similar(226108509,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msisdn</th>\n",
       "      <th>watched_1</th>\n",
       "      <th>watched_2</th>\n",
       "      <th>watched_3</th>\n",
       "      <th>watched_4</th>\n",
       "      <th>watched_5</th>\n",
       "      <th>predicted_1</th>\n",
       "      <th>predicted_2</th>\n",
       "      <th>predicted_3</th>\n",
       "      <th>predicted_4</th>\n",
       "      <th>predicted_5</th>\n",
       "      <th>recom_1</th>\n",
       "      <th>recom_2</th>\n",
       "      <th>recom_3</th>\n",
       "      <th>recom_4</th>\n",
       "      <th>recom_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228943823</th>\n",
       "      <td>778556725</td>\n",
       "      <td>Mahadena Mutta EP 01</td>\n",
       "      <td>Ranja</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236145493</th>\n",
       "      <td>770546665</td>\n",
       "      <td>Adanga Maru</td>\n",
       "      <td>Live Musical show</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236218442</th>\n",
       "      <td>767402445</td>\n",
       "      <td>Sulanga (The Wind)</td>\n",
       "      <td>Age Vairaya 3</td>\n",
       "      <td>Iravukku Aayiram Kangal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242196200</th>\n",
       "      <td>772446959</td>\n",
       "      <td>White light</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242226264</th>\n",
       "      <td>771258587</td>\n",
       "      <td>Weda Beri Tarzan Mathisabayata</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "      <td>Kuttram 23</td>\n",
       "      <td>Ilakkaya Episode 4</td>\n",
       "      <td>The Next Move</td>\n",
       "      <td>Sudda Hami Episode 04</td>\n",
       "      <td>Ilakkaya Episode 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              msisdn                       watched_1          watched_2  \\\n",
       "228943823  778556725            Mahadena Mutta EP 01              Ranja   \n",
       "236145493  770546665                     Adanga Maru  Live Musical show   \n",
       "236218442  767402445              Sulanga (The Wind)      Age Vairaya 3   \n",
       "242196200  772446959                     White light               None   \n",
       "242226264  771258587  Weda Beri Tarzan Mathisabayata               None   \n",
       "\n",
       "                         watched_3 watched_4 watched_5 predicted_1  \\\n",
       "228943823                     None      None      None  Kuttram 23   \n",
       "236145493                     None      None      None  Kuttram 23   \n",
       "236218442  Iravukku Aayiram Kangal      None      None  Kuttram 23   \n",
       "242196200                     None      None      None  Kuttram 23   \n",
       "242226264                     None      None      None  Kuttram 23   \n",
       "\n",
       "                  predicted_2    predicted_3            predicted_4  \\\n",
       "228943823  Ilakkaya Episode 4  The Next Move  Sudda Hami Episode 04   \n",
       "236145493  Ilakkaya Episode 4  The Next Move  Sudda Hami Episode 04   \n",
       "236218442  Ilakkaya Episode 4  The Next Move  Sudda Hami Episode 04   \n",
       "242196200  Ilakkaya Episode 4  The Next Move  Sudda Hami Episode 04   \n",
       "242226264  Ilakkaya Episode 4  The Next Move  Sudda Hami Episode 04   \n",
       "\n",
       "                   predicted_5     recom_1             recom_2        recom_3  \\\n",
       "228943823  Ilakkaya Episode 10  Kuttram 23  Ilakkaya Episode 4  The Next Move   \n",
       "236145493  Ilakkaya Episode 10  Kuttram 23  Ilakkaya Episode 4  The Next Move   \n",
       "236218442  Ilakkaya Episode 10  Kuttram 23  Ilakkaya Episode 4  The Next Move   \n",
       "242196200  Ilakkaya Episode 10  Kuttram 23  Ilakkaya Episode 4  The Next Move   \n",
       "242226264  Ilakkaya Episode 10  Kuttram 23  Ilakkaya Episode 4  The Next Move   \n",
       "\n",
       "                         recom_4              recom_5  \n",
       "228943823  Sudda Hami Episode 04  Ilakkaya Episode 10  \n",
       "236145493  Sudda Hami Episode 04  Ilakkaya Episode 10  \n",
       "236218442  Sudda Hami Episode 04  Ilakkaya Episode 10  \n",
       "242196200  Sudda Hami Episode 04  Ilakkaya Episode 10  \n",
       "242226264  Sudda Hami Episode 04  Ilakkaya Episode 10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is to get the list of users and recommended content\n",
    "def get_movies(data, test_base):\n",
    "    user_id_list = test_base['USER_ID'].to_list()\n",
    "    test_base.set_index('USER_ID', inplace=True)\n",
    "    output = {}\n",
    "\n",
    "    for user in user_id_list:\n",
    "        if user in user_list:\n",
    "            watched_list, Predicted_result, recommended_result = get_similar(user ,data)\n",
    "            \n",
    "            output[user] = [test_base.loc[user]['MSISDN']]\n",
    "            for i in range(1,6):\n",
    "                if i > len(watched_list['TITLE'].tolist()):\n",
    "                    output[user].append(None)\n",
    "                else:    \n",
    "                    output[user].append(watched_list['TITLE'].tolist()[i-1])\n",
    "            for i in range(1,6):\n",
    "                if i > len(Predicted_result['TITLE'].tolist()):\n",
    "                    output[user].append(None)\n",
    "                else:    \n",
    "                    output[user].append(Predicted_result['TITLE'].tolist()[i-1])\n",
    "            for i in range(1,6):\n",
    "                if i > len(recommended_result['TITLE'].tolist()):\n",
    "                    output[user].append(None)\n",
    "                else:    \n",
    "                    output[user].append(recommended_result['TITLE'].tolist()[i-1])\n",
    "        \n",
    "# #         output[user]['recommendations'] = recommendations.tolist()\n",
    "# #         output[user]['watched'] = user_full['TITLE'].tolist()[:5]\n",
    "# #         output[user]['predicted'] = predicted.index.tolist()[:5]\n",
    "    return output\n",
    "\n",
    "## Running the function\n",
    "# test_base = pd.read_csv('unsubscribed_viu.txt', sep='|', encoding='unicode_escape')\n",
    "data_list = get_movies(data, test_base)\n",
    "\n",
    "final = pd.DataFrame.from_dict(data_list, orient='index',\n",
    "                       columns=['msisdn','watched_1','watched_2','watched_3','watched_4','watched_5',\n",
    "                                'predicted_1', 'predicted_2', 'predicted_3', 'predicted_4', 'predicted_5', \n",
    "                                'recom_1', 'recom_2', 'recom_3', 'recom_4', 'recom_5'])\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
